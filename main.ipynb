{
 "cells": [
  {
   "cell_type": "code",
   "id": "b2819bfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:18:54.377910Z",
     "start_time": "2025-05-13T04:18:54.369648Z"
    }
   },
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "import torch\n",
    "from torch import nn, optim, Tensor\n",
    " \n",
    "from torch_sparse import SparseTensor, matmul\n",
    " \n",
    "from torch_geometric.utils import structured_negative_sampling\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.typing import Adj\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ],
   "outputs": [],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "id": "d8cafe45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:18:54.581372Z",
     "start_time": "2025-05-13T04:18:54.410534Z"
    }
   },
   "source": [
    "from data_loader import loader\n",
    "database = \"music\"\n",
    "rating_threshold = 4\n",
    "data_loader = loader(database)\n",
    "edge_index, edge_arr, num_users, num_items, user_mapping, movie_mapping =data_loader.read_data(database,rating_threshold)"
   ],
   "outputs": [],
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "id": "2a523b6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:18:54.590417Z",
     "start_time": "2025-05-13T04:18:54.584664Z"
    }
   },
   "source": [
    "class LightGCN(MessagePassing):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=64, K=3, add_self_loops=False, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_users (int): 用户数量\n",
    "            num_items (int): 电影数量\n",
    "            embedding_dim (int, optional): 嵌入维度，设置为64，后续可以调整观察效果\n",
    "            K (int, optional): 传递层数，设置为3，后续可以调整观察效果\n",
    "            add_self_loops (bool, optional): 传递时加不加自身节点，设置为不加\n",
    "        \"\"\"\n",
    "        kwargs.setdefault('aggr', 'add')\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_users, self.num_items = num_users, num_items\n",
    "        self.embedding_dim, self.K = embedding_dim, K\n",
    "        self.add_self_loops = add_self_loops\n",
    " \n",
    "        self.users_emb = nn.Embedding(\n",
    "            num_embeddings=self.num_users, embedding_dim=self.embedding_dim)  # e_u^0\n",
    "        self.items_emb = nn.Embedding(\n",
    "            num_embeddings=self.num_items, embedding_dim=self.embedding_dim)  # e_i^0\n",
    " \n",
    "        nn.init.normal_(self.users_emb.weight, std=0.1)  # 从给定均值和标准差的正态分布N(mean, std)中生成值，填充输入的张量或变量\n",
    "        nn.init.normal_(self.items_emb.weight, std=0.1)\n",
    " \n",
    "    def forward(self, edge_index: SparseTensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            edge_index (SparseTensor): 邻接矩阵\n",
    "        Returns:\n",
    "            tuple (Tensor): e_u%^k, e_u^0, e_i^k, e_i^0\n",
    "        \"\"\"\n",
    "        # compute \\tilde{A}: symmetrically normalized adjacency matrix\n",
    "        edge_index_norm = gcn_norm(\n",
    "            edge_index, add_self_loops=self.add_self_loops)\n",
    " \n",
    "        emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight]) # E^0\n",
    "        embs = [emb_0]\n",
    "        emb_k = emb_0\n",
    " \n",
    "        # 多尺度扩散\n",
    "        for i in range(self.K):\n",
    "            emb_k = self.propagate(edge_index_norm, x=emb_k)\n",
    "            embs.append(emb_k)\n",
    " \n",
    "        embs = torch.stack(embs, dim=1)\n",
    "        emb_final = torch.mean(embs, dim=1)  # E^K\n",
    " \n",
    "        users_emb_final, items_emb_final = torch.split(\n",
    "            emb_final, [self.num_users, self.num_items])  # splits into e_u^K and e_i^K\n",
    " \n",
    "        # returns e_u^K, e_u^0, e_i^K, e_i^0\n",
    "        return users_emb_final, self.users_emb.weight, items_emb_final, self.items_emb.weight\n",
    " \n",
    "    def message(self, x_j: Tensor) -> Tensor:\n",
    "        return x_j\n",
    " \n",
    "    def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
    "        # computes \\tilde{A} @ x\n",
    "        return matmul(adj_t, x)"
   ],
   "outputs": [],
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "id": "ba5cde88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:18:54.618761Z",
     "start_time": "2025-05-13T04:18:54.600821Z"
    }
   },
   "source": [
    "model = LightGCN(num_users, num_movies)"
   ],
   "outputs": [],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "id": "4198f20e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:18:54.630874Z",
     "start_time": "2025-05-13T04:18:54.628019Z"
    }
   },
   "source": [
    "def bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, lambda_val):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        users_emb_final (torch.Tensor): e_u^k\n",
    "        users_emb_0 (torch.Tensor): e_u^0\n",
    "        pos_items_emb_final (torch.Tensor): positive e_i^k\n",
    "        pos_items_emb_0 (torch.Tensor): positive e_i^0\n",
    "        neg_items_emb_final (torch.Tensor): negative e_i^k\n",
    "        neg_items_emb_0 (torch.Tensor): negative e_i^0\n",
    "        lambda_val (float): λ的值\n",
    "    Returns:\n",
    "        torch.Tensor: loss值\n",
    "    \"\"\"\n",
    "    reg_loss = lambda_val * (users_emb_0.norm(2).pow(2) +\n",
    "                             pos_items_emb_0.norm(2).pow(2) +\n",
    "                             neg_items_emb_0.norm(2).pow(2))  # L2 loss L2范数是指向量各元素的平方和然后求平方根\n",
    " \n",
    "    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n",
    "    pos_scores = torch.sum(pos_scores, dim=-1) # 正采样预测分数\n",
    "    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n",
    "    neg_scores = torch.sum(neg_scores, dim=-1) # 负采样预测分数\n",
    " \n",
    "    loss = -torch.mean(torch.nn.functional.softplus(pos_scores - neg_scores)) + reg_loss\n",
    " \n",
    "    return loss"
   ],
   "outputs": [],
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "id": "7f02416d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:18:54.642086Z",
     "start_time": "2025-05-13T04:18:54.639844Z"
    }
   },
   "source": [
    "def get_user_positive_items(edge_index):\n",
    "    \"\"\"为每个用户生成正采样字典\n",
    "    Args:\n",
    "        edge_index (torch.Tensor): 2*N的边列表\n",
    "    Returns:\n",
    "        dict: 每个用户的正采样字典\n",
    "    \"\"\"\n",
    "    user_pos_items = {}\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        user = edge_index[0][i].item()\n",
    "        item = edge_index[1][i].item()\n",
    "        if user not in user_pos_items:\n",
    "            user_pos_items[user] = []\n",
    "        user_pos_items[user].append(item)\n",
    "    return user_pos_items"
   ],
   "outputs": [],
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "id": "86c1c9aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:18:54.654350Z",
     "start_time": "2025-05-13T04:18:54.651573Z"
    }
   },
   "source": [
    "def RecallPrecision_ATk(groundTruth, r, k):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        groundTruth (list): 每个用户对应电影列表的高评分项\n",
    "        r (list): 是否向每个用户推荐了前k个电影的列表\n",
    "        k (intg): 确定要计算精度和召回率的前k个电影\n",
    "    Returns:\n",
    "        tuple: recall @ k, precision @ k\n",
    "    \"\"\"\n",
    "    num_correct_pred = torch.sum(r, dim=-1)  # number of correctly predicted items per user\n",
    "    # number of items liked by each user in the test set\n",
    "    user_num_liked = torch.Tensor([len(groundTruth[i])\n",
    "                                  for i in range(len(groundTruth))])\n",
    "    recall = torch.mean(num_correct_pred / user_num_liked)\n",
    "    precision = torch.mean(num_correct_pred) / k\n",
    "    return recall.item(), precision.item()"
   ],
   "outputs": [],
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "id": "f5c33409",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:18:54.667425Z",
     "start_time": "2025-05-13T04:18:54.663880Z"
    }
   },
   "source": [
    "def NDCGatK_r(groundTruth, r, k):\n",
    "    \"\"\"Computes Normalized Discounted Cumulative Gain (NDCG) @ k\n",
    "    Args:\n",
    "        groundTruth (list): 同上一个函数\n",
    "        r (list): 同上一个函数\n",
    "        k (int): 同上一个函数\n",
    "    Returns:\n",
    "        float: ndcg @ k\n",
    "    \"\"\"\n",
    "    assert len(r) == len(groundTruth)\n",
    " \n",
    "    test_matrix = torch.zeros((len(r), k))\n",
    " \n",
    "    for i, items in enumerate(groundTruth):\n",
    "        length = min(len(items), k)\n",
    "        test_matrix[i, :length] = 1\n",
    "    max_r = test_matrix\n",
    "    idcg = torch.sum(max_r * 1. / torch.log2(torch.arange(2, k + 2)), axis=1)\n",
    "    dcg = r * (1. / torch.log2(torch.arange(2, k + 2)))\n",
    "    dcg = torch.sum(dcg, axis=1)\n",
    "    idcg[idcg == 0.] = 1.\n",
    "    ndcg = dcg / idcg\n",
    "    ndcg[torch.isnan(ndcg)] = 0.\n",
    "    return torch.mean(ndcg).item()"
   ],
   "outputs": [],
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "id": "fbdd764c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:18:54.681197Z",
     "start_time": "2025-05-13T04:18:54.677389Z"
    }
   },
   "source": [
    "def get_metrics(model, edge_index, exclude_edge_indices, k):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model (LighGCN): lightgcn model\n",
    "        edge_index (torch.Tensor): 2*N列表\n",
    "        exclude_edge_indices ([type]): 2*N列表\n",
    "        k (int): 前多少个电影\n",
    "    Returns:\n",
    "        tuple: recall @ k, precision @ k, ndcg @ k\n",
    "    \"\"\"\n",
    "    user_embedding = model.users_emb.weight\n",
    "    item_embedding = model.items_emb.weight\n",
    " \n",
    "    # get ratings between every user and item - shape is num users x num movies\n",
    "    rating = torch.matmul(user_embedding, item_embedding.T)\n",
    " \n",
    "    for exclude_edge_index in exclude_edge_indices:\n",
    "        # gets all the positive items for each user from the edge index\n",
    "        user_pos_items = get_user_positive_items(exclude_edge_index)\n",
    "        # get coordinates of all edges to exclude\n",
    "        exclude_users = []\n",
    "        exclude_items = []\n",
    "        for user, items in user_pos_items.items():\n",
    "            exclude_users.extend([user] * len(items))\n",
    "            exclude_items.extend(items)\n",
    " \n",
    "        # set ratings of excluded edges to large negative value\n",
    "        rating[exclude_users, exclude_items] = -(1 << 10)\n",
    " \n",
    "    # get the top k recommended items for each user\n",
    "    _, top_K_items = torch.topk(rating, k=k)\n",
    " \n",
    "    # get all unique users in evaluated split\n",
    "    users = edge_index[0].unique()\n",
    " \n",
    "    test_user_pos_items = get_user_positive_items(edge_index)\n",
    " \n",
    "    # convert test user pos items dictionary into a list\n",
    "    test_user_pos_items_list = [\n",
    "        test_user_pos_items[user.item()] for user in users]\n",
    " \n",
    "    # determine the correctness of topk predictions\n",
    "    r = []\n",
    "    for user in users:\n",
    "        ground_truth_items = test_user_pos_items[user.item()]\n",
    "        label = list(map(lambda x: x in ground_truth_items, top_K_items[user]))\n",
    "        r.append(label)\n",
    "    r = torch.Tensor(np.array(r).astype('float'))\n",
    " \n",
    "    recall, precision = RecallPrecision_ATk(test_user_pos_items_list, r, k)\n",
    "    ndcg = NDCGatK_r(test_user_pos_items_list, r, k)\n",
    " \n",
    "    return recall, precision, ndcg"
   ],
   "outputs": [],
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "id": "defef1ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:18:54.693953Z",
     "start_time": "2025-05-13T04:18:54.690797Z"
    }
   },
   "source": [
    "def evaluation(model, edge_index, sparse_edge_index, exclude_edge_indices, k, lambda_val):\n",
    "    # get embeddings\n",
    "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
    "        sparse_edge_index)\n",
    "    edges = structured_negative_sampling(\n",
    "        edge_index, contains_neg_self_loops=False)\n",
    "    user_indices, pos_item_indices, neg_item_indices = edges[0], edges[1], edges[2]\n",
    "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
    "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
    "        pos_item_indices], items_emb_0[pos_item_indices]\n",
    "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[\n",
    "        neg_item_indices], items_emb_0[neg_item_indices]\n",
    " \n",
    "    loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0,\n",
    "                    neg_items_emb_final, neg_items_emb_0, lambda_val).item()\n",
    " \n",
    "    recall, precision, ndcg = get_metrics(\n",
    "        model, edge_index, exclude_edge_indices, k)\n",
    " \n",
    "    return loss, recall, precision, ndcg"
   ],
   "outputs": [],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "id": "b7900437",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:18:54.705577Z",
     "start_time": "2025-05-13T04:18:54.703210Z"
    }
   },
   "source": [
    "ITERATIONS = 10000\n",
    "BATCH_SIZE = 1024\n",
    "LR = 1e-3\n",
    "ITERS_PER_EVAL = 200\n",
    "ITERS_PER_LR_DECAY = 200\n",
    "K = 20\n",
    "LAMBDA = 1e-6"
   ],
   "outputs": [],
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "id": "d67ebe42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:18:54.716978Z",
     "start_time": "2025-05-13T04:18:54.715235Z"
    }
   },
   "source": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
   "outputs": [],
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "id": "77fdf363",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:18:54.732765Z",
     "start_time": "2025-05-13T04:18:54.725914Z"
    }
   },
   "source": [
    "train_sparse_edge_index = SparseTensor(row=train_edge_index[0], col=train_edge_index[1], sparse_sizes=(\n",
    "    num_users + num_movies, num_users + num_movies))\n",
    "val_sparse_edge_index = SparseTensor(row=val_edge_index[0], col=val_edge_index[1], sparse_sizes=(\n",
    "    num_users + num_movies, num_users + num_movies))\n",
    "test_sparse_edge_index = SparseTensor(row=test_edge_index[0], col=test_edge_index[1], sparse_sizes=(\n",
    "    num_users + num_movies, num_users + num_movies))"
   ],
   "outputs": [],
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "id": "82e783ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:18:54.746034Z",
     "start_time": "2025-05-13T04:18:54.742492Z"
    }
   },
   "source": [
    "model = model.to(device)\n",
    "model.train()\n",
    " \n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    " \n",
    "edge_index = edge_index.to(device)\n",
    "train_edge_index = train_edge_index.to(device)\n",
    "train_sparse_edge_index = train_sparse_edge_index.to(device)\n",
    " \n",
    "val_edge_index = val_edge_index.to(device)\n",
    "val_sparse_edge_index = val_sparse_edge_index.to(device)"
   ],
   "outputs": [],
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "id": "fce73ed8",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-13T04:18:54.755415Z"
    }
   },
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    " \n",
    "for iter in range(ITERATIONS):\n",
    "    # forward propagation\n",
    "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
    "        train_sparse_edge_index)\n",
    " \n",
    "    # mini batching\n",
    "    user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(\n",
    "        BATCH_SIZE, train_edge_index)\n",
    "    user_indices, pos_item_indices, neg_item_indices = user_indices.to(\n",
    "        device), pos_item_indices.to(device), neg_item_indices.to(device)\n",
    "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
    "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
    "        pos_item_indices], items_emb_0[pos_item_indices]\n",
    "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[\n",
    "        neg_item_indices], items_emb_0[neg_item_indices]\n",
    " \n",
    "    # loss computation\n",
    "    train_loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final,\n",
    "                          pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, LAMBDA)\n",
    " \n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    " \n",
    "    if iter % ITERS_PER_EVAL == 0:\n",
    "        model.eval()\n",
    "        val_loss, recall, precision, ndcg = evaluation(\n",
    "            model, val_edge_index, val_sparse_edge_index, [train_edge_index], K, LAMBDA)\n",
    "        print(f\"[Iteration {iter}/{ITERATIONS}] train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss, 5)}, val_recall@{K}: {round(recall, 5)}, val_precision@{K}: {round(precision, 5)}, val_ndcg@{K}: {round(ndcg, 5)}\")\n",
    "        train_losses.append(train_loss.item())\n",
    "        val_losses.append(val_loss)\n",
    "        model.train()\n",
    " \n",
    "    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
    "        scheduler.step()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 0/10000] train_loss: -0.69128, val_loss: -0.68373, val_recall@20: 0.00084, val_precision@20: 0.00036, val_ndcg@20: 0.0005\n",
      "[Iteration 200/10000] train_loss: -0.70111, val_loss: -0.69127, val_recall@20: 0.06307, val_precision@20: 0.0217, val_ndcg@20: 0.04763\n",
      "[Iteration 400/10000] train_loss: -0.89309, val_loss: -0.84182, val_recall@20: 0.13648, val_precision@20: 0.04033, val_ndcg@20: 0.09891\n",
      "[Iteration 600/10000] train_loss: -1.77237, val_loss: -1.56948, val_recall@20: 0.14475, val_precision@20: 0.04331, val_ndcg@20: 0.10352\n",
      "[Iteration 800/10000] train_loss: -3.48263, val_loss: -2.91514, val_recall@20: 0.14016, val_precision@20: 0.04322, val_ndcg@20: 0.10284\n",
      "[Iteration 1000/10000] train_loss: -5.62604, val_loss: -4.51969, val_recall@20: 0.14823, val_precision@20: 0.04476, val_ndcg@20: 0.10508\n",
      "[Iteration 1200/10000] train_loss: -7.84595, val_loss: -6.3726, val_recall@20: 0.14788, val_precision@20: 0.04485, val_ndcg@20: 0.10529\n",
      "[Iteration 1400/10000] train_loss: -9.51377, val_loss: -8.29319, val_recall@20: 0.15081, val_precision@20: 0.0453, val_ndcg@20: 0.10667\n",
      "[Iteration 1600/10000] train_loss: -13.06265, val_loss: -10.1815, val_recall@20: 0.151, val_precision@20: 0.04566, val_ndcg@20: 0.10554\n",
      "[Iteration 1800/10000] train_loss: -14.80282, val_loss: -12.10855, val_recall@20: 0.15045, val_precision@20: 0.0453, val_ndcg@20: 0.10627\n",
      "[Iteration 2000/10000] train_loss: -17.14124, val_loss: -14.3338, val_recall@20: 0.15194, val_precision@20: 0.04593, val_ndcg@20: 0.1059\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7326c1a9",
   "metadata": {},
   "source": [
    "iters = [iter * ITERS_PER_EVAL for iter in range(len(train_losses))]\n",
    "plt.plot(iters, train_losses, label='train')\n",
    "plt.plot(iters, val_losses, label='validation')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.title('training and validation loss curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
